# ğŸ§  ê¸°ì´ˆë¶€í„° ì‹œì‘í•˜ëŠ” ì¸ê³µì§€ëŠ¥ ëª¨ë¸ (PyTorch ë²„ì „)

ì´ ì €ì¥ì†ŒëŠ” ìì—°ì–´ ì²˜ë¦¬(NLP)ì™€ ì‚¬ìš©ì ê²½í—˜(CV) ê¸°ë°˜ì˜ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì„ PyTorchë¡œ êµ¬í˜„í•˜ë©°, ê¸°ì´ˆë¶€í„° ì‹¬í™”ê¹Œì§€ ì°¨ê³„ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## íŠœí† ë¦¬ì–¼ ëª©ë¡

### íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬ (NLP)

- [NLP 1: í…ìŠ¤íŠ¸ ì „ì²´ ì²˜ë¦¬ì™€ ì›Œë“œ ì„ë²¤ë“œ](https://johyeongseob.tistory.com/49)  
- [NLP 2: ìˆœíšŒ ì‹œê°„ë ¥ë²” (RNN, LSTM, GRU)](https://johyeongseob.tistory.com/50)  
- [NLP 3: ì–´í…ì…˜ê³¼ Seq2Seq ëª¨ë¸](https://johyeongseob.tistory.com/51)  

### íŠ¹ìˆ˜ ê·œì • ëª¨ë¸

- [Transformer (Vaswani et al., 2017)](https://johyeongseob.tistory.com/53)  
  - ë…¼ë¬¸: *Attention Is All You Need*  
- [Vision Transformer (ViT) (Dosovitskiy et al., 2020)](https://johyeongseob.tistory.com/71)  
  - ë…¼ë¬¸: *An Image is Worth 16x16 Words*  
- [CLIP (Radford et al., 2021)](https://johyeongseob.tistory.com/72)  
  - ë…¼ë¬¸: *Learning Transferable Visual Models from Natural Language Supervision*  

## ì‚¬ìš© ê¸°ìˆ 

- Python
- PyTorch
- Jupyter Notebook
- Hugging Face Transformers (uc120íƒì ìœ¼ë¡œ í™œìš©)

## ì°¸ê³  ë…¼ë¬¸

1. Vaswani et al., â€œAttention is All You Needâ€, NeurIPS 2017.  
2. Dosovitskiy et al., â€œAn Image is Worth 16x16 Wordsâ€, arXiv 2020.  
3. Radford et al., â€œLearning Transferable Visual Models from Natural Language Supervisionâ€, ICML 2021.

