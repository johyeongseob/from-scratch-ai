# 🧠 기초부터 시작하는 인공지능 모델 (PyTorch 버전)

이 저장소는 자연어 처리(NLP)와 사용자 경험(CV) 기반의 인공지능 모델을 PyTorch로 구현하며, 기초부터 심화까지 차계적으로 학습할 수 있도록 구성되어 있습니다.

## 튜토리얼 목록

### 특수 문자 처리 (NLP)

- [NLP 1: 텍스트 전체 처리와 워드 임벤드](https://johyeongseob.tistory.com/49)  
- [NLP 2: 순회 시간력범 (RNN, LSTM, GRU)](https://johyeongseob.tistory.com/50)  
- [NLP 3: 어텐션과 Seq2Seq 모델](https://johyeongseob.tistory.com/51)  

### 특수 규정 모델

- [Transformer (Vaswani et al., 2017)](https://johyeongseob.tistory.com/53)  
  - 논문: *Attention Is All You Need*  
- [Vision Transformer (ViT) (Dosovitskiy et al., 2020)](https://johyeongseob.tistory.com/71)  
  - 논문: *An Image is Worth 16x16 Words*  
- [CLIP (Radford et al., 2021)](https://johyeongseob.tistory.com/72)  
  - 논문: *Learning Transferable Visual Models from Natural Language Supervision*  

## 사용 기술

- Python
- PyTorch
- Jupyter Notebook
- Hugging Face Transformers (uc120택적으로 활용)

## 참고 논문

1. Vaswani et al., “Attention is All You Need”, NeurIPS 2017.  
2. Dosovitskiy et al., “An Image is Worth 16x16 Words”, arXiv 2020.  
3. Radford et al., “Learning Transferable Visual Models from Natural Language Supervision”, ICML 2021.

